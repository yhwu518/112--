{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyObUY/iqD9X16KMWgK588Lp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","import time\n"],"metadata":{"id":"_B9EnN_vRe-A","executionInfo":{"status":"ok","timestamp":1699117520602,"user_tz":-480,"elapsed":2780,"user":{"displayName":"YunHan Wu","userId":"13565354945171801437"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.layers import Conv2D, Dropout, Flatten, Dense, Reshape, Conv2DTranspose, ReLU, BatchNormalization, LeakyReLU\n","from tensorflow import keras\n","import tensorflow as tf"],"metadata":{"id":"CNlX-woHTL5O","executionInfo":{"status":"ok","timestamp":1699117583371,"user_tz":-480,"elapsed":2,"user":{"displayName":"YunHan Wu","userId":"13565354945171801437"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt"],"metadata":{"id":"2uGow7ugTb2i","executionInfo":{"status":"ok","timestamp":1699117649271,"user_tz":-480,"elapsed":1099,"user":{"displayName":"YunHan Wu","userId":"13565354945171801437"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def mnist_uni_gen_cnn(input_shape):\n","    return keras.Sequential([\n","        # [n, latent] -> [n, 7 * 7 * 128] -> [n, 7, 7, 128]\n","        Dense(7 * 7 * 128, input_shape=input_shape),\n","        BatchNormalization(),\n","        ReLU(),\n","        Reshape((7, 7, 128)),\n","        # -> [n, 14, 14, 64]\n","        Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same'),\n","        BatchNormalization(),\n","        ReLU(),\n","        # -> [n, 28, 28, 32]\n","        Conv2DTranspose(32, (4, 4), strides=(2, 2), padding='same'),\n","        BatchNormalization(),\n","        ReLU(),\n","        # -> [n, 28, 28, 1]\n","        Conv2D(1, (4, 4), padding='same', activation=keras.activations.tanh)\n","    ])\n","\n","\n","def mnist_uni_disc_cnn(input_shape=(28, 28, 1), use_bn=True):\n","    model = keras.Sequential()\n","    # [n, 28, 28, n] -> [n, 14, 14, 64]\n","    model.add(Conv2D(64, (4, 4), strides=(2, 2), padding='same', input_shape=input_shape))\n","    if use_bn:\n","        model.add(BatchNormalization())\n","    model.add(LeakyReLU())\n","    model.add(Dropout(0.3))\n","    # -> [n, 7, 7, 128]\n","    model.add(Conv2D(128, (4, 4), strides=(2, 2), padding='same'))\n","    if use_bn:\n","        model.add(BatchNormalization())\n","    model.add(LeakyReLU())\n","    model.add(Dropout(0.3))\n","    model.add(Flatten())\n","    return model\n"],"metadata":{"id":"aDwRHQBtSupP","executionInfo":{"status":"ok","timestamp":1699117591208,"user_tz":-480,"elapsed":3,"user":{"displayName":"YunHan Wu","userId":"13565354945171801437"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from tensorflow import keras\n","import tensorflow as tf\n","import os\n","import numpy as np\n","\n","MNIST_PATH = \"./mnist.npz\"\n","\n","\n","def load_mnist(path):\n","    if os.path.isfile(path):\n","        with np.load(path, allow_pickle=True) as f:\n","            x_train, y_train = f['x_train'], f['y_train']\n","            x_test, y_test = f['x_test'], f['y_test']\n","        return (x_train, y_train), (x_test, y_test)\n","    return keras.datasets.mnist.load_data(MNIST_PATH)\n","\n","\n","def get_half_batch_ds(batch_size):\n","    return get_ds(batch_size//2)\n","\n","\n","def get_ds(batch_size):\n","    (x, y), _ = load_mnist(MNIST_PATH)\n","    x = _process_x(x)\n","    y = tf.cast(y, tf.int32)\n","    ds = tf.data.Dataset.from_tensor_slices((x, y)).cache().shuffle(1024).batch(batch_size) \\\n","        .prefetch(tf.data.experimental.AUTOTUNE)\n","    return ds\n","\n","\n","def get_test_x():\n","    (_, _), (x, _) = load_mnist(MNIST_PATH)\n","    x = _process_x(x)\n","    return x\n","\n","\n","def get_test_69():\n","    _, (x, y) = load_mnist(MNIST_PATH)\n","    return _process_x(x[y == 6]), _process_x(x[y == 9])\n","\n","\n","def get_train_x():\n","    (x, _), _ = load_mnist(MNIST_PATH)\n","    x = _process_x(x)\n","    return x\n","\n","\n","def _process_x(x):\n","    return tf.expand_dims(tf.cast(x, tf.float32), axis=3) / 255. * 2 - 1\n","\n","\n","def get_69_ds():\n","    (x, y), _ = load_mnist(MNIST_PATH)\n","    x6, x9 = x[y == 6], x[y == 9]\n","    return _process_x(x6), _process_x(x9)\n","\n","\n","def downsampling(imgs, to_shape):\n","    s = to_shape[:2]\n","    imgs = tf.random.normal(imgs.shape, 0, 0.2) + imgs\n","    return tf.image.resize(imgs, size=s)"],"metadata":{"id":"SyskiiS5Smi9","executionInfo":{"status":"ok","timestamp":1699117593599,"user_tz":-480,"elapsed":3,"user":{"displayName":"YunHan Wu","userId":"13565354945171801437"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def set_soft_gpu(soft_gpu):\n","    if soft_gpu:\n","        gpus = tf.config.experimental.list_physical_devices('GPU')\n","        if gpus:\n","            # Currently, memory growth needs to be the same across GPUs\n","            for gpu in gpus:\n","                tf.config.experimental.set_memory_growth(gpu, True)\n","            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")"],"metadata":{"id":"1DuCvccXSdJt","executionInfo":{"status":"ok","timestamp":1699117597036,"user_tz":-480,"elapsed":1,"user":{"displayName":"YunHan Wu","userId":"13565354945171801437"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def save_weights(model):\n","    name = model.__class__.__name__.lower()\n","    os.makedirs(\"./models/{}\".format(name), exist_ok=True)\n","    model.save_weights(\"./models/{}/model.ckpt\".format(name))"],"metadata":{"id":"HjLxTJITSgJ_","executionInfo":{"status":"ok","timestamp":1699117598575,"user_tz":-480,"elapsed":2,"user":{"displayName":"YunHan Wu","userId":"13565354945171801437"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def save_gan(model, ep, **kwargs):\n","    name = model.__class__.__name__.lower()\n","    if name in [\"dcgan\", \"wgan\", \"wgangp\", \"lsgan\", \"wgandiv\", \"sagan\", \"pggan\"]:\n","        imgs = model.call(100, training=False).numpy()\n","        _save_gan(name, ep, imgs, show_label=False)\n","    elif name == \"gan\":\n","        data = model.call(5, training=False).numpy()\n","        plt.plot(data.T)\n","        plt.xticks((), ())\n","        dir_ = \"visual/{}\".format(name)\n","        os.makedirs(dir_, exist_ok=True)\n","        path = dir_ + \"/{}.png\".format(ep)\n","        plt.savefig(path)\n","    elif name == \"cgan\" or name == \"acgan\":\n","        img_label = np.arange(0, 10).astype(np.int32).repeat(10, axis=0)\n","        imgs = model.predict(img_label)\n","        _save_gan(name, ep, imgs, show_label=True)\n","    elif name in [\"infogan\"]:\n","        img_label = np.arange(0, model.label_dim).astype(np.int32).repeat(10, axis=0)\n","        img_style = np.concatenate(\n","            [np.linspace(-model.style_scale, model.style_scale, 10)] * 10).reshape((100, 1)).repeat(model.style_dim, axis=1).astype(np.float32)\n","        img_info = img_label, img_style\n","        imgs = model.predict(img_info)\n","        _save_gan(name, ep, imgs, show_label=False)\n","\n","\n","    elif name == \"stylegan\":\n","        n = 12\n","        global z1, z2       # z1 row, z2 col\n","        if \"z1\" not in globals():\n","            z1 = np.random.normal(0, 1, size=(n, 1, model.latent_dim))\n","        if \"z2\" not in globals():\n","            z2 = np.random.normal(0, 1, size=(n, 1, model.latent_dim))\n","        imgs = model.predict([\n","            np.concatenate(\n","                (z1.repeat(n, axis=0).repeat(1, axis=1), np.repeat(np.concatenate([z2 for _ in range(n)], axis=0), 2, axis=1)),\n","                axis=1),\n","            np.zeros([len(z1)*n, model.img_shape[0], model.img_shape[1]], dtype=np.float32)])\n","        z1_imgs = -model.predict([z1.repeat(model.n_style, axis=1), np.zeros([len(z1), model.img_shape[0], model.img_shape[1]], dtype=np.float32)])\n","        z2_imgs = -model.predict([z2.repeat(model.n_style, axis=1), np.zeros([len(z2), model.img_shape[0], model.img_shape[1]], dtype=np.float32)])\n","        imgs = np.concatenate([z2_imgs, imgs], axis=0)\n","        rest_imgs = np.concatenate([np.ones([1, 28, 28, 1], dtype=np.float32), z1_imgs], axis=0)\n","        for i in range(len(rest_imgs)):\n","            imgs = np.concatenate([imgs[:i*(n+1)], rest_imgs[i:i+1], imgs[i*(n+1):]], axis=0)\n","        _save_gan(name, ep, imgs, show_label=False, nc=n+1, nr=n+1)\n","    else:\n","        raise ValueError(name)\n","    plt.clf()\n","    plt.close()\n","\n","def _img_recenter(img):\n","    return (img + 1) * 255 / 2"],"metadata":{"id":"ADbtqtOiSTNM","executionInfo":{"status":"ok","timestamp":1699117670844,"user_tz":-480,"elapsed":1077,"user":{"displayName":"YunHan Wu","userId":"13565354945171801437"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def _save_gan(model_name, ep, imgs, show_label=False, nc=10, nr=10):\n","    if not isinstance(imgs, np.ndarray):\n","        imgs = imgs.numpy()\n","    if imgs.ndim > 3:\n","        imgs = np.squeeze(imgs, axis=-1)\n","    imgs = _img_recenter(imgs)\n","    plt.clf()\n","    plt.figure(0, (nc * 2, nr * 2))\n","    for c in range(nc):\n","        for r in range(nr):\n","            i = r * nc + c\n","            plt.subplot(nr, nc, i + 1)\n","            plt.imshow(imgs[i], cmap=\"gray_r\")\n","            plt.axis(\"off\")\n","            if show_label:\n","                plt.text(23, 26, int(r), fontsize=23)\n","    plt.tight_layout()\n","    dir_ = \"visual/{}\".format(model_name)\n","    os.makedirs(dir_, exist_ok=True)\n","    path = dir_ + \"/{}.png\".format(ep)\n","    plt.savefig(path)\n","\n"],"metadata":{"id":"tduLQC06TW-O","executionInfo":{"status":"ok","timestamp":1699117674324,"user_tz":-480,"elapsed":643,"user":{"displayName":"YunHan Wu","userId":"13565354945171801437"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def cvt_gif(folders_or_gan, shrink=10):\n","    if not isinstance(folders_or_gan, list):\n","        folders_or_gan = [folders_or_gan.__class__.__name__.lower()]\n","    for folder in folders_or_gan:\n","        folder = \"visual/\"+folder\n","        fs = [folder+\"/\" + f for f in os.listdir(folder)]\n","        imgs = []\n","        for f in sorted(fs, key=os.path.getmtime):\n","            if not f.endswith(\".png\"):\n","                continue\n","            try:\n","                int(os.path.basename(f).split(\".\")[0])\n","            except ValueError:\n","                continue\n","            img = Image.open(f)\n","            img = img.resize((img.width//shrink, img.height//shrink), Image.ANTIALIAS)\n","            imgs.append(img)\n","        path = \"{}/generating.gif\".format(folder)\n","        if os.path.exists(path):\n","            os.remove(path)\n","        imgs[-1].save(path, append_images=imgs, optimize=False, save_all=True, duration=400, loop=0)\n","        print(\"saved \", path)"],"metadata":{"id":"SvMVhIv3SOrZ","executionInfo":{"status":"ok","timestamp":1699117678332,"user_tz":-480,"elapsed":770,"user":{"displayName":"YunHan Wu","userId":"13565354945171801437"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"pzE3N51HRYhH","executionInfo":{"status":"error","timestamp":1699123339388,"user_tz":-480,"elapsed":4994629,"user":{"displayName":"YunHan Wu","userId":"13565354945171801437"}},"outputId":"4b4a9c4e-5cbf-4aa4-c1b2-27eec4263653"},"outputs":[{"output_type":"stream","name":"stdout","text":["1 Physical GPUs, 1 Logical GPUs\n","Model: \"sequential_8\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_8 (Dense)             (None, 6272)              633472    \n","                                                                 \n"," batch_normalization_18 (Ba  (None, 6272)              25088     \n"," tchNormalization)                                               \n","                                                                 \n"," re_lu_12 (ReLU)             (None, 6272)              0         \n","                                                                 \n"," reshape_4 (Reshape)         (None, 7, 7, 128)         0         \n","                                                                 \n"," conv2d_transpose_8 (Conv2D  (None, 14, 14, 64)        131136    \n"," Transpose)                                                      \n","                                                                 \n"," batch_normalization_19 (Ba  (None, 14, 14, 64)        256       \n"," tchNormalization)                                               \n","                                                                 \n"," re_lu_13 (ReLU)             (None, 14, 14, 64)        0         \n","                                                                 \n"," conv2d_transpose_9 (Conv2D  (None, 28, 28, 32)        32800     \n"," Transpose)                                                      \n","                                                                 \n"," batch_normalization_20 (Ba  (None, 28, 28, 32)        128       \n"," tchNormalization)                                               \n","                                                                 \n"," re_lu_14 (ReLU)             (None, 28, 28, 32)        0         \n","                                                                 \n"," conv2d_12 (Conv2D)          (None, 28, 28, 1)         513       \n","                                                                 \n","=================================================================\n","Total params: 823393 (3.14 MB)\n","Trainable params: 810657 (3.09 MB)\n","Non-trainable params: 12736 (49.75 KB)\n","_________________________________________________________________\n","Model: \"critic\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," sequential_9 (Sequential)   (None, 6272)              133056    \n","                                                                 \n"," dense_9 (Dense)             (None, 1)                 6273      \n","                                                                 \n","=================================================================\n","Total params: 139329 (544.25 KB)\n","Trainable params: 138945 (542.75 KB)\n","Non-trainable params: 384 (1.50 KB)\n","_________________________________________________________________\n","t=0 | time=0.3 | d_loss=-0.00 | g_loss=-0.00\n","t=1000 | time=249.3 | d_loss=-0.00 | g_loss=-0.00\n","t=2000 | time=248.5 | d_loss=-0.00 | g_loss=0.00\n","t=3000 | time=254.8 | d_loss=-0.00 | g_loss=-0.00\n","t=4000 | time=248.4 | d_loss=-0.00 | g_loss=0.00\n","t=5000 | time=248.1 | d_loss=0.00 | g_loss=0.00\n","t=6000 | time=249.9 | d_loss=-0.00 | g_loss=0.01\n","t=7000 | time=248.2 | d_loss=-0.00 | g_loss=0.01\n","t=8000 | time=249.1 | d_loss=-0.00 | g_loss=0.00\n","t=9000 | time=247.7 | d_loss=0.00 | g_loss=0.00\n","t=10000 | time=250.8 | d_loss=-0.00 | g_loss=0.01\n","t=11000 | time=247.8 | d_loss=-0.00 | g_loss=0.00\n","t=12000 | time=248.3 | d_loss=0.00 | g_loss=-0.01\n","t=13000 | time=248.5 | d_loss=-0.00 | g_loss=-0.01\n","t=14000 | time=247.6 | d_loss=-0.00 | g_loss=-0.01\n","t=15000 | time=250.7 | d_loss=-0.00 | g_loss=0.00\n","t=16000 | time=246.6 | d_loss=-0.00 | g_loss=0.00\n","t=17000 | time=247.9 | d_loss=-0.00 | g_loss=-0.00\n","t=18000 | time=248.6 | d_loss=0.00 | g_loss=-0.00\n","t=19000 | time=257.1 | d_loss=-0.00 | g_loss=0.00\n","t=20000 | time=250.7 | d_loss=0.00 | g_loss=-0.00\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-2a8117b4b564>\u001b[0m in \u001b[0;36m<cell line: 85>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_train_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLATENT_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_SHAPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTEP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_LOOP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-15-2a8117b4b564>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(gan, ds, steps, d_loop, batch_size)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0msave_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mcvt_gif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-1f20faf954d3>\u001b[0m in \u001b[0;36mcvt_gif\u001b[0;34m(folders_or_gan, shrink)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mshrink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mshrink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mANTIALIAS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 0 Axes>"]},"metadata":{}}],"source":["class WGAN(keras.Model):\n","    \"\"\"\n","    Wasserstein 距离作为损失函数， 避免D太强导致G的梯度消失。\n","    D 最大化 Wasserstein 距离，提高收敛性\n","    G 最小化 Wasserstein 距离\n","    Clip D weights，局限住太强的 D，让 G 可以跟上 (Lipschitz 约束)。\n","    \"\"\"\n","    def __init__(self, latent_dim, clip, img_shape):\n","        super().__init__()\n","        self.latent_dim = latent_dim\n","        self.clip = clip\n","        self.img_shape = img_shape\n","        self.opt = tf.keras.optimizers.legacy.Adam(0.0002, beta_1=0, beta_2=0.9)\n","        self.g = self._get_generator()\n","        self._build_d()\n","\n","    def _build_d(self):\n","        self.d = self._get_discriminator()\n","\n","    def call(self, n, training=None, mask=None):\n","        return self.g.call(tf.random.normal((n, self.latent_dim)), training=training)\n","\n","    def _get_generator(self):\n","        model = mnist_uni_gen_cnn((self.latent_dim,))\n","        model.summary()\n","        return model\n","\n","    def _get_discriminator(self, use_bn=True):\n","        model = keras.Sequential([\n","            mnist_uni_disc_cnn(self.img_shape, use_bn),\n","            keras.layers.Dense(1)\n","        ], name=\"critic\")\n","        model.summary()\n","        return model\n","\n","    @staticmethod\n","    def w_distance(fake, real=None):\n","        # the distance of two data distributions\n","        if real is None:\n","            return tf.reduce_mean(fake)\n","        else:\n","            return tf.reduce_mean(fake) - tf.reduce_mean(real)\n","\n","    def train_d(self, real_img):\n","        with tf.GradientTape() as tape:\n","            fake_img = self.call(len(real_img), training=False)\n","            pred_real = self.d.call(real_img, training=True)\n","            pred_fake = self.d.call(fake_img, training=True)\n","            loss = self.w_distance(pred_fake, pred_real)   # maximize W distance\n","        grads = tape.gradient(loss, self.d.trainable_variables)\n","        self.opt.apply_gradients(zip(grads, self.d.trainable_variables))\n","        # clip discriminator's weights\n","        for w in self.d.trainable_weights:\n","            w.assign(tf.clip_by_value(w, -self.clip, self.clip))\n","        return loss\n","\n","    def train_g(self, n):\n","        with tf.GradientTape() as tape:\n","            g_img = self.call(n, training=True)\n","            pred_fake = self.d.call(g_img, training=False)\n","            loss = -self.w_distance(pred_fake)       # minimize W distance\n","        grads = tape.gradient(loss, self.g.trainable_variables)\n","        self.opt.apply_gradients(zip(grads, self.g.trainable_variables))\n","        return loss\n","\n","\n","def train(gan, ds, steps, d_loop, batch_size):\n","    t0 = time.time()\n","    for t in range(steps):\n","        for _ in range(d_loop):\n","            idx = np.random.randint(0, len(ds), batch_size)\n","            real_img = tf.gather(ds, idx)\n","            d_loss = gan.train_d(real_img)\n","        g_loss = gan.train_g(batch_size)\n","        if t % 1000 == 0:\n","            t1 = time.time()\n","            print(\"t={} | time={:.1f} | d_loss={:.2f} | g_loss={:.2f}\".format(\n","                    t, t1 - t0, d_loss.numpy(), g_loss.numpy(), ))\n","            t0 = t1\n","            save_gan(gan, t)\n","    save_weights(gan)\n","    cvt_gif(gan)\n","\n","\n","if __name__ == \"__main__\":\n","    LATENT_DIM = 100\n","    CLIP = 0.01\n","    D_LOOP = 5\n","    IMG_SHAPE = (28, 28, 1)\n","    BATCH_SIZE = 64\n","    STEP = 20001\n","\n","    set_soft_gpu(True)\n","    d = get_train_x()\n","    m = WGAN(LATENT_DIM, CLIP, IMG_SHAPE)\n","    train(m, d, STEP, D_LOOP, BATCH_SIZE)"]}]}